# Fail back before upstream claim [#3556](https://github.com/lightningdevkit/rust-lightning/pull/3556/commits/a78ea1ffe68cfa3f4b438bd7a1d52f2fe63d90b0)

- `PendingHtlcRouting` represents different types of htlcs that we can
  relay; the other variants already have the incoming cltv set because
  they're for receives and it's needed for final cltv delta check
- `HTLCPreviousHopData` stores the things that we need to remember about
  the htlc when we settle/fail it back (shared secret/blinding stuff
  etc).
  - This is persisted, so old forwards won't have it stored (option),
    added to the impl_writable_tlv_based macro to persist
  - Used in two places in the codebase:
    - ClaimableHTLC: a htlc terminating at our node, we could claim
    - HTLCSource: an outgoing htlc, if it was forwarded to us

Q: failed_back_htlc_ids is in-memory only, how does this behave after
   restart? Assuming that we'll hit the code that re-checks them and
   re-adds?
  - It's repopulated (and de-dupped) every time that block_connected
    is called (called by both transactions_confirmed and 
    best_block_updated), surfaced via `ChannelMonitor`
  - Couldn't find docs on how the end user is supposed to be using this,
    but they _must_ call `advance_chain` after a restart

O: what does the change to `update_monitor` do?
- `ChannelMonitor` has an inner implementation that's `Mutex`ed
  - `chainmonitor`/`update_channel`
  - `util`/`read_channel_monitor_with_updates`: reads from disk and
    performs updates that have been read
- `update_monitor`:
  - Applies a set of updates to the channel monitor
  - If we've already gone to chain, only expecting a force close or
    preimage disclosure
  - Iterate through each update and apply them, tracking any errors that
    may have been encountered (eg, we continue with updates even if 
    there's an invalid counterparty commit secret and only finish it
    at the end)
  - Even if everything was applied successfully, we error out if the
    counterparty has tried to apply an update when we know that the
    funding tx has been spent
  - `holder_tx_signed` bool that was added is set once we've handed
    off a commitment to the `OnChainTxHandler`

Q: Is there test coverage for these cases?
- `test_update_replay_panics` has a few tests for update monitor
- Drains down to 4 updates but then only asserts the state on 3 of 
  them? The one before is a "normal" update unrelated to the test case.
- There's a comment from 4766e99e6f saying that we should panic,
  but there is a panic in 4766e99e6f for the code being tested?
  [ ] Outstanding, not sure what the comment refers to (outdated w/ PR)
- The force close transaction will set `lockdown_from_offchain` to true
  (because the test does a local force close, it sets broadcast to true)
- If we could get the counterparty to set up a pre_close_update at
  the end of our queue, then we could add some coverage here.
  [ ] Could probably try to send an update_fee at the end of this test
  to trigger a unit tests

Possible Side Quests:
- PR removes a fuzz test, take a look at how that commit works
(historical_inbound_htlc_fulfills)
- Take another look at htlc flow, specifically how these pieces fit in
- How does LDK node handle restarts (links into being unsure about where
  the external api for announcing new blocks is, specifically after
  a restart).
- What happens in the case where we force close and broadcast but the
  counterparty doesn't know yet and sends an update? They don't know
  we're going to chain but we're going to error out of `update_channel`

