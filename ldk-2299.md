Didn't push temp file form work PC, creating this in the meantime.

`send_payment_for_trampoline_forward`
- Create a new payment secret for payment to next trampoline, and
  a recipient onion that just has a payment secret.
- We then query for a route to the destination.
- `add_new_pending_payment`:
  - Add an entry to `pending_outbound_payments`
  - Creates a `Retryable` payment
  - Generate the onion private keys for the chosen path
- `pay_route_internal`:
  - Performs some checks on the route
  - Calls `send_payment_along_path` which actually dispatches
  - `handle_pay_route_err` will perform any state updates needed
    if we can't dispatch the payment
  - We return an appropriate error for the payment

- [x] Added validation to `send_payment_internal` to make sure we only
  have forwarding fields in the payload.

- [x] Moving up `send_payment_along_path` change so that it's usable
  before our trampoline send commit.

- Creates a session private key for the payment being dispatched
- Create an `onion_packet, htlc_msat, htlc_cltv` for the info (1)
- Gets the channel we're sending over
- Creates the HTLC source (using `previous_hop_data` that we put in
  `trampoline_forward_info`.
- `send_htlc_and_commit` to dispatch the HTLC
- Does all the regular error handling 

(1) `create_trampoline_forward_onion`
- Creates an outer onion which pays the final amount in the path
  to the trampoline node that's receive it
- [ ] Takes a `keysend_preimage` that we shouldn't have?
- Builds the onion path for the outer onion using `final_value_msat`
- Creates recipient data for the trampoline
- Looks at the last onion paylaod we've created (must be a receive)
  - If unblinded, we add `TrampolineEntrypoint`
  - If blinded, we add `BlindedTrampolineEntrypoint`
- We overwrite the `last_payload`
- Finally, create onion keys and packet with the path and onion
  payloads provided

Q: what's the difference between `path.final_value_msat` and the 
  `total_msat` that's passed in here?
Q: would we ever pass in a `keysend_preimage` here?

(1) `create_payment_onion` (calls straight to `create_payment_onion_internal`:
- If there is a blinded tail
  - If there are trampoline payments
  - `build_trampoline_onion_payloads`
  - Create session private keys for trampoline
  - Construct onion keys for trampoline
  - Create onion packets for trampoline w/ keys
- `build_onion_payloads`
- Finally, construct onion keys and onion packet and payloads

- [ ] Issue:
- When we're the ones to build the trampoline payloads, we only
  support them if they're blinded
- When we receive the already built payload in a forwarding scenario,
  we have to cover both cases.

Going back to look into the payload types we support, I don't love the
claude suggestion for refactor here.

The types of outer onions we receive `InboundOnionPayload`:
- `Forward`: regular, no blinding
- `TrampolineEntrypoint`:
  - Could have `FinalOnionHopData` if if we've been MPP-ed to
  - Contains an inner onion packet (which we unwrawp)
  - `current_path_key`: we need to include this for the next node to
    unwrap their trampoline onion
  -> Basically, end of the outer onion time to do trampoline
- `Receive`: regular receive
- `BlindedForward`: blinded forwarding node gets routing info
- `BlindedReceive`: blinded recipient gets receive info

Types of inner trampoline onions we receive:
- `Forward`: we've been given the next node id to forward to
- `BlindedForward`: we're forwarding and get our routing info out of
  an encrypted data blob.
- `Receive`: we're the final recipient, but we looked like a trampoline
  to the previous node.
- `BlindedReceive`: we're the final recipient, and we got our recipient
  information out of encrypted data.

The types of ourter onions we create `OutboundOnionPayload`:
- `Forward`: regular forwading hop
- `TrampolineEntrypoint`: this is a trampoline and it gets the inner
  onions in its payload.
- `BlindedTrampolineEntrypoint`: this is a trampoline and it gets
  inner onions in its payload, along with a blinding point to help
  decrypt the inner onions.
- `Receive`:  regular receive
- `BlindedForward`: include encrypted tlvs for this node which has the
  forwarding information that it needs.
- `BlindedReceive`: was part of a blinded route, include final info 

The types of inner onions we create: `OutbountTrampolinePayload`:
- `Forward` + `Receive` regular fwd/recv inter-trampoline
  - Note: we don't support receiving unblinded
- `LegacyBlindedPathEntry`: end of trampoline, can send to blinded paths
- `BlindedForward`: include encrypted tlvs for node to get fwd info
- `BlindedReceive`: was part of a blinded route, include final info

Going back to our problem:
- `create_payment_onion_internal`:
  - Will create trampoline onions _if_ we have them in a blinded tail
  - Builds outer onion which will have these trampoline payloads in the
    last hop.

- `create_trampoline_forward_onion`:
  - Builds outer onion with the trampoline onion packet, creating a
    fake recipient onion for the final node
  - Gets the last onion payload that we've just built, which is a
    regular receive onion
    - Replaces it with either a `TrampolineEntrypoint` or a
      `BlindedTrampolineEntrypoint`

Q: Why can't we have trampoline packets in our path for inter-trampoline?
- We're picking a destination, and we don't have a blinded path from
  them to pay to.
- If we're a trapoline paying to a blinded path we have a
  `LegacyBlindedPathEntry` which isn't dealt with as a forwad (?)

Q: What are all the different case we need to handle?

Sending:
- Last trampoline is recipient:
  - Unblinded: sender includes final hop details in trampoline onion
  - Blinded: sender includes encrypted data in trampoline onion
- Exit to blinded path:
  - Sender receives a blinded path
  - Instructs last trampoline to route to introduction node
  - Puts blinded path information inside of subsequent trampoline
    payloads (blinded forward + blinded receive).

`build_onion_payloads_callback`:
- If we have `BlindedTailDetails::DirectEntry`:
  - Create a blinded receive at the end of the route
  - Create blinded forwards up until it, providing blinding point to
    the first one (the introduction node)
- If we have `BlindedTailDetails::TrampolineEntry`:
  - If there's a blinding point present, create `BlindedTrampolineEntrypoint`
  - Otherwise create `TrampolineEntrypoint`

Key difference:
- `DirectEntry`: we're just using a blinded path, and we should push
  multiple hops into our path for blinded forwards.
- `TrampolineEntry`: we're using trampoline forwading, and should push
  a trampoline onion which has already wrapped each of our blinded
  payloads in subsequent inner onions.

Note: LDK only supports the case where we're given a blinded path and
put the information inside of the trampoline onions, using each hop as
a blinded trampoline.

Thoughts:
- We should just be able to provide the right type of iter and we'll be
  fine? When we have a pre-built trampoline packet it's just a
  TrampolineEntrypoint?
- we need to call `build_onion_payloads_callback` with a TrampolineEntrypoint

Forwarding:
- When we receive a payload with a trampoline onion inside of it, we
  decode the inner onion and distinguish between the following:
  - `TrampolineForward`: given pubkey of next node
  - `BlindedFoward`: given forwarding details inside of blinded data
  - `Receive`: we're receiving and the person who sent knows it
  - `BlindedRecieve`: we've received via a blinded path
  - We fail if:
    - We get a forward with no next hop data
    - We get a receive with next hop data
- Regardless of whether we got a `TrampolineForward` or a
  `TrampolineBlindedForward`, we'll create `NextPacketDetails` with
  the pubkey of the next node in it.

Note: LDK doesn't currently support the case where you just throw some
blinded paths into the *outer* onion and then make a payment to them.
This is a workaround for when the recipient doesn't support trampoline.
I'm not sure whether we need to do this?

Note: For now, I'm going to ignore the above case and just work with
the "everyone supports trampoline" case.

Issue:
- We only add a `TrampolineEntry` if we've got a blinded path and there
  is Some `trampoline_packet`.
- For forwading, we may have a `trampoline_packet` which doesn't have
  any blinded path attached to it.

Q: I think that pairing the blinded path with trampoline was a mistake
that comes from only wanting to support them together in receives?
- In a world where 

## ln: handle trampoline without validating in process pending

It's okay to not process because they'll go from here to process
receives.

## Incoming HTLC Accumulation

We need to accumulate in the same way that we do for MPP payments.
- `process_receive_htlcs` is the starting point for all of this
- This will be called for _every_ incoming trampoline HTLC that arrives.

What does this do:
- Go through each pending_forward
- Match on the type 
- Creates a ClaimableHTLC struct
- Starts to track `committed_to_claimable` 
- Check if we konw the preimage, otherwise set to None
- Match on the `onion_payload` type to do checking for the
  specific type of receive (eg, check payment data, validate)
- Call `check_total_value`
 - Fail if we currently have a pending claim
 - Add to `claimable_payemnts`, noting if we're already
   `committed_to_claimable` (ie, an entry is already there)
  - Check that onion fields are the same 
  - Check the total amount on the HTLC is satisfied
    - Push to `claimable_payments` if it is ok
    - Pushes an event

What do we need to change:
- Add matching for trampoline payment
- Add an onion type (if avoid if we can) for trampoline
- Add a payment purpose for trampoline
- When we're fully accumulated, we should dispatch the payment

Q: what do we do with `pending_claimable`?

Breaking up what we have:
`outbound_payments`
- Add to `pay_route_internal`
- Add to `create_pending_payment`
- Add to `PendingOutbound`
- `send_payment_for_trampoline`
- `trampoline_htlc_failed` 

`channelmanager`
- `send_payment_along_path`:
  - creates onion for trampoline or payment
  - creates source accordingly
- `process_pending_update_add_htlcs`:
  - Adds trampoline to validation (but doesn't check it)
- `process_receive_htlcs`:
  ! This is what's going to need to change when we add accumulation !
  ! We still want all of this logic, but we need to call it after acc !
  - Processed blinding point
  - Calculates fees for trampoline
  - Setup parameters for trampoline payment
  - `send_payment_for_trampoline_forward` 
- `fail_backwards_internal`:
  - checks in with `outbound_payments` that we should actually fail back

Differences:
- Trampoline isn't a `ClaimablePayment`, we need the fields:
  - `fail_htlc` needs:
    - value
    - prev_hop
    - Need to push a HTLCSource (which isn't outbound payment)
  - `check_total_value` needs:
    - Purpose
    - Whether to push to claimable_payments or trampoline?
    - We want to merge onion fields (checks MPP data)
    - We need different actions on success (push event vs dispatch)
- Also want to have a pending trampoline mitigation

`check_claimable_payment`:

Q: Can we represent trampoline in `ClaimablePayment`?
- `prev_hop`: yes? can be represented by each one of the tram incoming?
- expiry + value + sender_intended_value: should all be good
- `OnionPayload`: need to add an option for trampoline
- timer_ticke/total_receives/total_msat: all should be fine?

Q: How can we handle locking? We need to hold `pending_outbound_payments`
   _before_ we hold `claimable_payments`

Action:
- Return a result with the `ClaimablePayment`, `amount_msat`, `earliest_expiry`
- Perform the success closure w/o holding the lock (?)

Note:
- Pulling out claimable_payments helper doesn't need to separate the
  guard because we're going to use a separate lock
- Make a macro for adding to timed_out_htlcs

Things we need that `claimable_payment` doesn't have:
- `incoming_trampoline_shared_secret`:
- `path`:
- `session_priv`:
- `payment_id`

For trampoline:
- We'll only have payments in this map if it's pending accumulation
- Once we've dispatched the payment we must remove it from the map.
  - On restart, we need to trim any pending things that might be waiting
- When we hit timeout, we should just fail everything back to keep it
  simple.
  - MPP: fail everything back
  - On chain: fail everything back

Trampoline will *wrap* claimable payment!

Q: Are we happy to fail all htlcs backwards when a trampoline payment
   has hit an expiry height.
  - Yes, we don't care

Q: Make HTLCSource's path option or move it?
- `send_payment_along_path`: path is passed in
  - `pay_route_internal`: we dispatch along each path, and store the
    high level route in the payment.
- `trampoline_htlc_failed`?
- `process_onion_failure`:
  - `process_onion_failure_inner` Q: do we have otherwise at inner
    - Needs `path` for attributable errors
- `decode_onion_failure`:
  - Ultimately needs to get path from source
-> This does seem to be like it belongs in `HTLCSource::TrampolineForward`,
   so will make it an option

Q: What is the difference between `onion_payload`, `payment_data` and
   `onion_fields`:
- `onion_paylaod`(`OnionPayload` enum)
  - Enum that tells us what type of payment this is (used below)
  - Contains preimage for keysend (which is a TLV in the outer onion)
  - Used to set the type on `ClaimableHTLC`
- `payment_data` (`FinalOnionHopData`):
  - Contains the `payment_secret` and `total_msat` used in MPP
  - Used to  set `total_msat` on `ClaimableHTLC`
  - If the recipient knows the preimage, we'll verify the payment
    with this data
- `onion_fields` (`RecipientOnionFields`):
  - Also contains the `payment_secret`, but has the `payment_metadata`
    and `custom_tlvs` too
  - In `check_claimable_incoming_htlcs` we merge these onion fields
    with the other claimable

The `onion_fields` belong to `ClaimablePayment`.
The `payment_data` belongs to the `ClaimableHTLC`.

Q: `payment_data` should possibly be `None` for trampoline?
- No, we use it to get our MPP totals
- We also use it if the recipient created the payment secret, but that's
  not the case for trampoline.
- We can choose to just not validate the `payment_data`

Q: Why is payment secret duplicated across `RecipientOnionFields` and
   `FinalHopData`?
- This just seems to be legacy / odd but I'm not going to refactor
  it further.

Current refactor isn't working:
- Pull out `handle_claimable_payment` and do locking in there.
- Pull out `handle_trampoline_payment` and do locking in there.
- They can both call down to `check_claimable_incoming_htlcs`

Move fields from AwaitingTrampolinePayment to inside of onion

I need to provide the following for fail_htlc:
- htlc_source
- HTLCFailReason
- HTLCHandlingFailureType

Previously: we had a single `prev_hop` that we want to fail, now we
want to fail back the whole trampoline (which may have multiple sources).

## Available Information

How do we parse trampoline payloads?
- `UpdateAddHTLC` has all of our incoming values (amt + CLTV)
- `decode_incoming_update_add_htlc_onion` parses next hop:
  - `TrampolineForward`:
    - `InboundTrampolineForwardPayload`:
      - Has `amt_to_forward` (the outgoing amount)
      - Has `outgoing_cltv_value`
      - Has `next_trampoline`
    - `trampoline_shared_secret`: secret to decrypt the trampoline onion
    - `incoming_trampoline_public_key`
  - `TrampolineBlindedForward`:
    - `InboundTrampolineBlindedForwardPayload`:
      - Blinded values that we can derive our `amt_to_forward`/`outgoing_cltv_value`
      - `next_trampoline` included inside of blinding data
    - `outer_shared_secret`
    - `trampoline_shared_secret`
    - `incoming_trampoline_public_key`

We create `NextPacketDetails`:
- `next_packet_pubkey`: the ephemeral key to use for the trampoline
- `outgoing_connector`: the pubkey we should route to
- outgoing amount/cltv

This is fed into `get_pending_htlc_info`:
- We create `RoutingInfo::Trampoline`:
  - `next_trampoline`: Pubkey we need to route to
  - `next_packet_bytes`: the bytes of the next node's trampoline packet
  - `next_hop_hmac`: the hmac for the trampoline
  - MPP data

Q: what's the difference between `next_packet_pubkey` and `next_trampoline`?
- `next_packet_pubkey` is the ephemeral pubkey for making the onion,
  `next_trampoline` is who we route to.
- `inocming_amt_msat` + `amt_to_forward` is in `PendingHTLCInfo` upper struct
- `outgoing_cltv_value` + `outgoing_cltv_value` is in `PendingHTLCInfo` upper struct

Q: why do we care about the pubkey of the incoming trampoline?
- It's the ephemeral pubkey, I hate its name

# Spec Walkthrough

Running through spec and cross-checking handling of errors/blinding
points w/ how it's implemented in LDK.

Trampoline cases:
1) Trampoline to blinded path (last payload has blinded path to pay)
2) Trampoline to cleartext (just give node id for next trampoline)
3) Blinded trampoline (give blinded blob for next trampoline)

`TrampolineEntrypoint`:
- We don't know whether we're the receiving node or not yet, we just
  know that we're the last node and we have a trampoline packet to
  deal with.

Validation:
- If we're receiving, we check the amount/cltv against inner onion

For next hop:
- `current_path_key` should be used to decrypt trampoline onion
- `multipath_trampoline_data`: should be used to aggregate MPP.
- `trampoline_packet`: should be peeled to get receive or forward

When we decode our final hop incoming outer onion and detect that there
is a trampoline packet inside it, we know that we're either receiving
or forwarding the trampoline.

- Grab the packet ephemeral key from the `trampoline_packet`
- If there is a blinding `current_path_key` in the *outer* onion:
  - ecdh node key + blinding point to get shared secret w/ blinding pt
  - hmac it to get the node id tweak
- We then calculate the shared secret for our trampoline onion:
  - ecdh node key + trampoline ephemeral key (optionally tweaked w/ blinding)
- Now we decode the trampoline payload using the shared secret that we
  have derived from our node id, the ephemeral key of the trampoline
  packet and (optionally) the blinding point using `decode_next_hop`:
  - `trampoline_shared_secret`: just calculated
  - `trampoline_packet.hop_data`: inner onion
  - `trampoline_packet.hmac`: inner onion's hmac
  - `blinding_point`: blinding point passed in `update_add_htlc`
- There are various options that can pop out here (ignoring receives):
  - `InboundTrampolinePayload::Forward` + `InboundTrampolinePayload::BlindedForward`:
    - Has the outer trampoline data
    - Trampoline ephemeral key
    - Trampoline shared secret
    - `next_trampoline_hop_data`:
      - `Forward`: has next node ID, amt and cltv
      - `Blinded`:
        - has next node ID
        - blinding calculation stuff (for amt + cltv)
        - `intro_node_blinding_point`: inner onion's intro node blinding point
        - `next_blinding_override`: from blinded blob inside inner onion
      Note: we haven't tweaked these keys for the next node yet, we're
      just passing on our *current* values.
- When we have a `TrampolineForward` or `TrampolineBlindedForward`,
  we'll `create_fwd_pending_htlc_info` which created `RoutingInfo::Trampoline`:
  - `next_trampoline`: the pubkey of the next node we need to fwd to
  - `new_trampoline_packet_bytes/hmac`:  onion values to use for next tramp
  - `shared_secret`: the *current* shared secret for this trampoline
  - `current_path_key`: blinding point from outer onion
  - `intro_node_blinding_point`: blinding point from inner onion
  - `next_blinding_override`: blinding override from inner onion's encrypted data
    - Q: Can we remove `current_path_key` from `RoutingInfo::Trampoline`?
      -> We seem to set `outer_onion.current_path_key` to the same value
         as `next_blinding_override` in `create_fwd_pending_htlc_info`?
- Now we create `PendingHTLCRouting::TrampolineForward`:
  - `incoming_shared_secret`: the shared secret of the incoming trampoline
  - `onion_packet`: the trampoline we should include for the next node
  - `incoming_cltv_epiry`
  - `node_id`: the pubkey of the next trampoline
  - `blinded`:
    - If we had a blinding point in the inner onion (introduction node)
    - Or we have a blinding point in the outer onion (relaying node)
    -> Create a `BlindedForward` which has the correct current
       `inbound_blinding_point` and `next_blinding_override`, and set
       correct error
    *Note*: we still haven't tweaked this!

Q: Why do we need to tweak the trampoline shared secret?
- If we are a blinded trampoline relay node, we'll have a
  `current_path_key` included in our outer payload.
  (introduction nodes get the blinding point inside their trampoline)
- The original sending node was given a blinded path with blinded node
  IDs (it doesn't know our real one) and had to create the inner onion
  with these blinded node ids. 

Q: What blinding points do we need to deal with for `BlindedForward`?
- When we are the introduction node, the blinding point that we'll need
  to include for the next node is in our _inner_ payload (cause the
  original sender put it in there).
- When we are the relaying node, the blinding point that we'll need to
  include for the next node is in our _outer_ payload (cause the last
  trampoline put it there).

Q: Do we have support to forwarding out to a blinded path?
- No, we don't even parse it!
- It would be Type 21 + 22 in the onion, which we can't even decode
- We'd need to be able ot make our `next_trampoline` a destination that
  we can give the router (clear vs blinded)

- Code walkthrough
  - [x] We do need to thread through multipath so that we can check
        the accumulating MPPs arriving
  - [x] I don't think we need `incoming_trampoline_shared_secret`

## Test Debugging

### Blinded Points

How should blinded trampolines be using the blinding key:
- Introduction node:
  - Gets blinding point from inside of trampoline onion
  - Uses it to decrypt its encrypted data to figure out who to forward
    it to next
  - Needs to include blinding point in the payload for the _next_ node
    in the outer onion. Q: how do we tweak it
- Relaying node:
  - Gets blinding point from inside of outer onion.
  - Uses it to decrypt its trampoline onion and encrypted data.
  - Needs to include blinding point in the payload for the _next_ node
    in the outer onion.

How do we handle blinding for a forward?
- We have a `blinded` field that tracks both the blinding point we
  received *and* any overrides that we received.
  - We set this to `intro_node_blinding_point` if it is present OR
  - `current_path_key` if no intro node
- When we create the `next_hop_info` we either use the
  `next_blinding_override` OR get the next blinding point from the
  existing inbound blinding point.

Issue:
- Dave can't decrypt his payload, which means that the blinding point
  carol sets is probably wrong.
- Carol can decrypt her encrypted data (to figure out to forward to D),
  so Alice is definitely setting the correct blinding point for Carol.

`create_fwd_pending_htlc_info`:
- This has been reviewed + merged a long time ago, so it must be where
  we're using it that's an issue.
- Using exactly the same blinding code as we do for regular forwards.

The decode error we're hitting is a `DecodeError` which makes me think
that the payload might be wrong? `ShortRead`

I think that onion construction is wrong. Need to take a proper look at
it.

Q: How does trampoline onion building work today?

- `build_trampoline_onion_payloads`:
  - We create a `DirectEntry` which contains all of our blinded hops
  - Give this to `build_onion_payloads_callback` (1) with our trampoline
    hops as the main set of hops we're interested in

(1) `build_onion_payloads_callback`
- Reverse our main set of hops
- Set `cltv` = delta of the last hop + offset
- Set `value_msat` = fee of the last hop
- For first hop:
  - If we have a direct entry blinded path:
    - For the last hop
      - Add the final value of the blinded path to `value_msat`
      - Add a blinded receive
    - Add a blinded forward
  - If we have a trampoline entry:
    - Add the final value of the trampoline hop `value_msat`
    - Add a trampoline entry
- Add other hops as usual

When we get to this stage, we already have our trampoline packet, which
should contain blinding data if it's a blinded trampoline. The
`new_trampoline_entry` creates a trampoline packet:
- `total_msat`: passed in above
- `amt_to_forward`: `TrampolineEntry.final_value_msat` + `hop.fee_msat()`

For example: `test_trampoline_onion_payload_assembly_values`
- We have two regular hops (Bob, Carol)
- We have a blinded tail with:
  - Trampolines: [Carol, Dave]
  - Blinded: [Dave blinded, Eve blinded]

We build our inner trampoline onion payloads and get 3:
- Carol: regular
- Dave: introduction 
- Eve: blinded recpiient

We then build our outer onion and get 2 payloads:
- Bob: regular trampoline forward
- Carol: trampoline entrypoint

This means that our code is able to understand that the *last* trampoline
hop must be the introduction node. Note also:
- The _first_ trampoline is duplicated in the last outer onion hop and
  the first trampoline hop.
- The _last_ trampoline hop is duplicated in the last trampoline hop
  and the first blinded hop.

Q: how do we mimic this when we *only* have a trampoline packet and
   no blinding information? And how do we set the correct amount/cltv?

- `create_payment_onion`
  - `create_payment_onion_internal`
    - `build_onion_payloads`:
      - `build_onion_payloads_callback(path hops, blinded tail)`


We call:
- `build_trampoline_onion_payloads`
- `build_onion_payloads`

What we want is:
- Able to pass in a trampoline packet to `build_onion_payloads`
- Able to differentiate between send case and foward case

What do we have at callsite:
- `total_value` of the payment we're sending
- `onion_packet`
- `blinding_point`
- `previous_hop_data`
- `incoming_trampoline_shared_secret`

We've already created a path with the CLTV/amount that we want.
Can we just use those values as our final value?

## New Tests

Testing blinded trampoline forward:

A - B - C (intro tramp) - D (fwd) - E (blinded tramp) - F (blinded recv)

F creates a blinded path w/ trampolines, selecting Carol and Eve as his
introduction and forwarding blinded hops plus himself. In this blinded
path he'll set:
- A final amount equal to the amount that he's expecting to receive
- Carol as the introduction trampoline
- Blinded payloads for Carol, Eve and Fred
  - He'll give Carol and Eve forwarding policies that they use to figure
    out their outgoing ???
- Total fee that should be paid for the entire blinded trampoline path
- Total CLTV that should be used for the entire blinded trampoline path

### CLTV Delta issues
What's happening w/ Dave?
- We are correctly setting our cltv delta for the path, but we're not
  appropriately setting the cltv value in the actual onion

We accept a starting_htlc_offset, this should be E's CLTV - done!
[ ] Need to commit this!

So, are we returning the correct value and cltv for D's incoming value?
And are we setting it correctly?
- I think we're hitting the starting condition twice because we don't
  have any cltv delta value on the receiving trampline

### Trampoline stops at E

Q: What type of payload does E think they're receiving?

CKC pushing to htlc_forwards: PendingHTLCInfo { routing: TrampolineForward { incoming_shared_secret: [85, 114, 153, 118, 170, 42, 24, 34, 180, 142, 7, 189, 156, 173, 164, 242, 252, 34, 83, 95, 21, 186, 138, 230, 30, 2, 147, 32, 62, 39, 210, 163], onion_packet: TrampolineOnionPacket version 0 with hmac [110, 15, 157, 34, 53, 249, 185, 133, 22, 255, 204, 239, 123, 56, 205, 35, 24, 19, 21, 100, 185, 70, 196, 186, 117, 113, 119, 127, 71, 213, 192, 205], node_id: PublicKey(51a89329f3c107b708bf8625bb8df5a2b15c8146549526bd57944ef61b3bf07d984f26946b2a09ef4c91eb3855e4c8cc6541ed8d04ecdc3eadcaff3d04d4adac), blinded: Some(BlindedForward { inbound_blinding_point: PublicKey(b8087a579d49f0ab5e59fda9b28828e59f59ba48bb5a2250b17866f938357a81ced4ccbce5003ea3fad30410d5d26d39b6978d1a50a6ae27039ad497b720b7c9), failure: FromBlindedNode, next_blinding_override: None }), incoming_cltv_expiry: 386, incoming_multipath_data: 

Some(FinalOnionHopData { 
payment_secret: 1727cb8ac414c2e5bfc83e0c81c6649e3027875ce0b83cc033d4c60961c4c6ea, 
total_msat: 2000
}) }, incoming_shared_secret: [126, 206, 197, 10, 127, 22, 9, 227, 137, 117, 97, 145, 180, 195, 200, 210, 158, 87, 74, 11, 123, 98, 66, 205, 103, 46, 106, 178, 246, 57, 252, 50], payment_hash: 66687aadf862bd776c8fc18b8e9f8e20089714856ee233b3902a591d0d5f2925, incoming_amt_msat: Some(2000), outgoing_amt_msat: 1000, outgoing_cltv_value: 338, skimmed_fee_msat: None }

What do we have:
- `total_value`: the amount the sender intended to give us for the HTLC (1000)
- `claimable_htlc.total_msat`: the MPP total across htlcs (2000)
- `amount_msat`: the amount that actually arrived at us

We are setting "sender_intended_value" wrong
- We are receiving 2000
- Our total MPP amount is 2000
- This is set from the `outgoing_amt_msat` that we have

Fix:
- Don't subtract the trampoline amount off of the `PendingHTLCRouting`
  amount (it's premature). Use it to accumulate in the claim htlc logic
  and then when it comes time to route, pull the right info out of
  our `next_trampoline_hop` to understand our fee diff.
- Also need to be including MPP payload for Carol's trampoline, not sure
  why we aren't doing that.

Q: When we have a blinded trampoline, should we expect an `amt_to_fwd`
   and a `outgoing_cltv` in the *outer* onion?
  - Yes, because it doesn't contain blinded data.

### Failures

We're hitting different failures for the various tests:

Unblinded:
- We're sending a payment with a blinded tail, and then registering
 
- `fail_htlc`:
  - If we `failed_within_blinded_path` then we'll report it
  - `insert_previously_failed_blinded_path`:
    - Iterate through all the blinded paths in our PaymentParameters
      - Match on hops and blinding point
      - Push this blinded path to our previously failed
      - Set the assert bool to true
    - Assert that we called fail with a blinded path that we know about
      for this payee

Our sender has a regular payment out (w/ a trampoline at the end):
- `decode_onion_failure`
  - `process_onion_failure`:
    - `process_onion_failure_inner` (1)

(1) `process_onion_failure_inner`:
- We assume that being in a trampoline means we're in a blinded path
  because they're really tightly coupled. This makes our assertion fail.

Blinded:
- We can't just use fail_backwards along path because we have blinding
  + trampoline involved
- Fred is sending back an update_fail_htlc from `check_trampoline_payment_constraints`
- Called by `create_recv_pending_htlc_info`
  - `peel_payment_onion`
  - `forwarding_channel_not_found`
  - `get_pending_htlc_info`

Each of the blinded trampoline nodes essentially act as their own
introduction node (because the blinding point is in the onion pld).
This means that we should expect:

### Trampoline Fees

Our outbound payments doesn't track:
1) The total amount of our incoming htlcs

Where are our tests failing:
- When we pass along route, we check the fee advertized by our outgoing
  channel
- This needs to match our event

What are the different states we should think about restarts?
- `awaiting_trampoline_forwards`/incomplete:
  - We haven't had all htlcs arrive yet, we'll wait for more or timeout.
- `awaiting_trampoline_forwards`/complete:
  - We've had all htlcs timeout, but have not yet dispatched a payment
  - We're happy to just leave these to time out; it's an edge case
- `awaiting_trampoline_forwards`/complete + payment dispatched:
  - Awaiting not deleted:
    - We've dispatched the payment but not yet deleted the trampoline
      from our awaiting payments
    - [ ] We need to find a way to reconcile the fields 
  - Awaiting deleted:
    - We've dispatched the payment and deleted from our awaiting payments
    - We're okay to continue with the source in the `pending_outbound_payment`

## Structure Runthrough

Want to make sure I'm not duplicating any information. Starting after
the regular commit cycle.

`internal_process_pending_htlc_forwards`
  - `process_pending_update_add_htlcs` (1)
  - `process_receive_htlcs` (2)

(1) `process_pending_update_add_htlcs`
- Go through each `decode_update_add_htlcs`
- `decode_incoming_update_add_htlc_onion`
  - `decode_next_payment_hop`: 
    - Decodes onion payload, matches on
      `InboundOnionPayload::TrampolineEntrypoint`
      - Contains *outer* onion's amt/value
      - Contains trampoline packet 
    - Also decodes inner onion payload, creating either a
      `Hop::Trampoline{Blinded}Forward`/`Hop::TrampolineReceive`
      - `outer_hop_data`: contains amt/cltv of outer onion
      - `next_trampoline_hop_data`: contains instructions from inner 
    - Matches on the `next_hop`:
      - `NextPacketDetails`:
        - Forward: uses inner trampoline values
        - Blinded: uses values we calculated from blinding params
- Checks whether inbound channel `can_accept_incoming_htlc` 
- Checks `can_forward_htlc_should_intercept`
  - Does basic CLTV validation
    !! But this is on our *inner* values
- `get_pending_htlc_info`
  - `create_fwd_pending_htlc_info`:
    - Matches on various hop types
    - This is where we `check_blinded_forward`
    - `PendingHTLCInfo`:
      - `outgoing_amt_msat`: set to value in outer onion 
      - `outgoing_cltv_value`: set to value in outer onion
      - routing: `TrampolineForward`: has trampoline amount/expiry
- Does various interception checks
- Pushes to `htlc_forwards` if doesn't need interception

(2) `process_receive_htlcs`:
- Match on the `HTLCForwardInfo::AddHTLC`
  - `cltv_expiry` = `incoming_cltv_expiry`
  - `NextTrampolineHopInfo`: contains trampoline amt/expiry
  - `onion_fields`:
    - MPP values from recipient field
    - or `outgoing_amt_msat` from *outer* onion
  - `ClaimableHTLC`:
    - `cltv_expiry`: Uses incoming cltv of HTLC
    - `sender_intended_value`: Uses outer onion for per-htlc amt
    - `total_msat`: Uses `payment_data` (fall back to outer onion)

## Commit Walkthrough

- Is a duplicate `SendHTLCId` an issue?
  Seems like this could lead to some suss repeat payment stuff. Leave
  as an expect and see what reviewers have to say.

- Is it possible for us to have a trampoline payment when we reach
  `forwarding_channel_not_found`?
  No, we handle trampoline payments as receives so they'd never reach
  this branch.

- When do we actually have a `None` `outbound_payment` on our
  `HTLCSource::TrampolinePayment`?
  When we're collecting inbound htlcs for a trampoline payment and
  want to fail them back appropriately we don't yet have a trampoline.
  We do need this to be a `HTLCSource::Trampoline` so that it'll
  handle our events properly.

- Where are we hitting `HTLCSentId` for a previous outbound?
  Our API for `fail_htlc_backwards_internal` isn't great - we provide
  the `HTLCHandlingFailureType` which is only used for
  `HTLCHandlingFailure` events (for forwards) even when we're failing
  back one of our own payments (eg, the channel is closing and we're
  failing back our outbound).

- Where do we need `path` in `HTLCSource::TrampolineForward`?
  We use it to `process_onion_failure_inner`: we check all sorts of
  stuff to figure what type of failure we're getting.

- What do we use `NextTrampolineInfo`'s `amount_msat` and
  `cltv_expiry_height` for?
  Q: can we just immediately switch out our outgoing onion's values
  with these values from the inner onion?
  We have `outgoing_amt_msat`/`outgoing_cltv_value` in PendingHTLCInfo
  We have `next_amount_msat`/`next_cltv_height` in `NextTrampolineInfo`

- Why do we need `previous_hop_data` in our `TrampolineForwardInfo`?
  If we want to be able to retry trampoline payments, we need to be
  able to re-create our payment information for our next payment (so
  that we can create a new `HTLCSource`). If we don't have this then
  we're not able to dispatch the payment.

- How do we recover from restarts/claim payments if we don't re-load
  our trampoline info?
  We don't actually use the information in our claims, only for
  retries.

- What blinding points should we set for trampoline? And what should
  we validate.
  When we have a trampoline forward, the blinding point in the outer
  onion acts like the `update_add_htlc` blinding point.

- Do we validate the `outgoing_cltv_value` for trampoline forwards?
  - We currently call `check_incoming_htlc` in:
    - `peel_payment_onion`
    - `can_forward_htlc_should_intercept`: won't be hit for tramps 

- What `total_msat` do we persist for `OnionPayload::TrampolinePaylaod`
  - We write `total_msat` value of claimable
  - 


Turn on + Test
==============
ln/test: add coverage for blinded and unblinded trampoline forwarding
a7e52e34c [deleteme]: remove assertion that fails on unblinded test
fd6ff6c84 ln/test: only use replacement onion in trampoline tests when needed
34dd131f3 ln: use correct blinding point for trampoline payload decodes
e4338a23e ln: process added trampoline htlcs with CLTV validation
90f75306d ln/refactor: pass minimum delta into check_incoming_htlc_cltv
a05b08d61 ln: add handling in malformed error handler
3b8053348 ln: only fail trampoline payments backwards when payment state ready
3316646c6 [wip]: handling function for trampoline dispatch
b0dc977d9 ln: add trampoline forward info to PendingOutboundPayment::Retryable
e2271a889 ln: use outer onion values for trampoline NextPacketDetails
dbcfe7fe7 ln: use outer onion cltv values in PendingHTLCInfo for trampoline
c1f198b89 ln: store next trampoline amount and cltv in PendingHTLCRouting

MPP Stuff
=========
a8e8a0b64 ln: move receive-specific failures into fail_htlc macro
d21e5bbbc ln: handle claimable htlcs for payments in dedicated method
91e29c2c4 ln/refactor: move checks on incoming mpp accumulation into method
222a13036 [wip]: add awaiting_trampoline_forwards to accumulate inbound MPP
54555550a [wip]: add Trampoline variant to OnionPayload
f10d71c96 ln/refactor: move on chain timeout check into claimable htlc
ca62019e0 ln/refactor: move mpp timeout check into helper function

Payment Stuff
=============
830c89b88 ln: Add utility to lookup forwarded trampoline fee
d0bd8944c [wip] ln: add trampoline htlc failure logic to outbound payments
68b15d2db ln/refactor: surface error data in DecodedOnionData for Trampolines
188b33ad0 ln: add send trampoline payment functionality
15f8c4265 ln: support trampoline in send_payment_along_path
5f15512d4 ln function to build trampoline forwarding onions
3ccd20a3d ln: add blinding point to new_trampoline_entry
3bc088945 ln: thread trampoline routing information through payment methods
b0dc977d9 ln: add trampoline forward info to PendingOutboundPayment::Retryable
e2271a889 ln: use outer onion values for trampoline NextPacketDetails
dbcfe7fe7 ln: use outer onion cltv values in PendingHTLCInfo for trampoline
c1f198b89 ln: store next trampoline amount and cltv in PendingHTLCRouting

Prefactor
=========
fcb9190cd ln: store incoming mpp data in PendingHTLCRouting
bdb68dae3 [upstream]: add failure_type helper to HTLCSource for HTLCHandlingFailureType
874fa189a [upstream] Remove attempted htlc from trampoline forward
06d9b8678 [upstream/squash]: make payment fields optional and include payment id
66ca6c93b ln: handle trampoline claims on restart
1ed00151d ln/refactor: move outgoing payment replay code into helper function
799828bf2 ln: add channel monitor recovery for trampoline forwards
3cd7dffc2 ln/refactor: extract channelmonitor recovery to external helper
d58d98f6b ln: add trampoline routing failure handling
b75cfd3c1 ln/refactor: add blinded forwarding failure helper function
1df50270a ln: add trampoline routing payment claiming
548321a2a ln/refactor: pass closure to create PaymentForwarded event
2d84b5709 ln/refactor: add claim funds for htlc forward helper
82c7f226a ln: add TrampolineForward variant to HTLCSource enum
a5d56a936 ln: add TrampolineForward SendHTLCId variant
f88dc807d events: add TrampolineForward variant to HTLCHandlingFailureType
712c6f042 ln+events: allow multiple prev_channel_id in HTLCHandlingFailed
77669c8bf ln/refactor: rename EmitEventAndFreeOtherChannel to note optional event
568eb83e0 ln: make event optional in EmitEventAndFreeOtherChannel
80cf43875 ln/events: multiple htlcs in/out for trampoline PaymentForwarded


This is what it'll look like:
pick 7c6d93f10 events: add TrampolineForward variant to HTLCHandlingFailureType
squash de28f9155 [upstream] Remove attempted htlc from trampoline forward
pick 85ed12eb9 ln: add TrampolineForward SendHTLCId variant
pick 6b6f3eb31 ln: add TrampolineForward variant to HTLCSource enum
squash d48c29611 [upstream/squash]: make payment fields optional and include payment id
reword fa3a6d4ff [upstream]: add failure_type helper to HTLCSource for HTLCHandlingFailureType

## Prefactor final runthrough

- Q: should we have optional htlcs in `HTLCHandlingFailure::Trampoline`?
  - `failure_type`: do we have htlcs available?
  - `fail_receive_htlc`: we have the source available
  - `timer_tick_occurred`: we have the previous hltcs available
  - `do_chain_event`: we have the htlcs available
  -> Other enum types have the _outgoing_ ID and channel that we failed
     on.

- Q: what happens when our "conditional fail back" runs into other
  types of fails (like fail because a channel is closing?):
  - `close_channel_internal`:
    - Builds a set of `failed_htlcs` from `chan.get_shutdown`:
      - Only for `LocalAnnounced` (we haven't sent to the remote yet)
    - Fails them back with `fail_htlc_backwards_internal`
    -> We'll have reported the failure to our pathfinding, but not yet
      failed the incoming htlcs back if we're still trying.
  - `finish_close_channel`:
    - Uses `ShutdownResult`, which populates with `LocalAnnounced` htlcs
      that the channel monitor doesn't yet know about.

- Q: where do we call failure_type?
  - `fail_holding_cell_htlcs`:
  - `post_monitor_update_unlock`:
  - `process_pending_monitor_updates`
  - `do_chain_event`:
  - `handle_in_flight_updates`:

- What data do we need to provide with `CLTVExpiryTooSoon`?
  -> Use existing helper, can just write a zero length channel update.

- `trampoline_htlc_failed` will panic if we call without path, but
  we need to be able to fail back w/o a path when we do MPP timeout 
  -> Updated this to just assert that we're not called without an
  outbound payment, and added some handling to the caller to deal
  with the issue of failures where we haven't sent a payment yet.

Error handling:

Recipient:
- `process_pending_update_add_htlcs`:
  - `create_recv_pending_htlc_info`:
    - Validates the received trampoline htlc
  - We push the local failure into `forward_htlcs(Relay/Malformed)`

## Address Review

`MonitorUpdateCompletionAction`:
- `monitor_update_blocked_actions`: once all of a channel's
  `ChannelMonitorUpdate` are complete, take these actions.
- These run after all *non-blocked* `ChannelMonitorUpdates`s
  have been persisted.
  - Primarily useful for preimage updates that bypass blocking.

Suggestion to use the exiting `FreeImmediately` option - makes sense
because the event is a bit weird now.


Non-Trampoline:
- When we have a duplicate, `FreeOtherChannelImmediately`
-  Only push `monitor_update_blocked_actions` *if* we don't have any
  `in_flight_monitor_updates` in `claim_mpp_part`

Trampoline (2x previous_hop_data):
- `claim_funds_from_htlc_forward_hop(prev_htlc_1)`
  `make_payment_forwarded_event` returns `Some`
  `completion_action` returns `EmitEventAndFreeOtherChannel`
  - `claim_funds_from_hop`:
    - Called with `prev_htlc_1` as previous hop
    - `claim_mpp_part`:
      - `get_update_fulfill_htlc_and_commit`:
        - Returns a `NewClaim`
      - Push action into `monitor_update_blocked_actions` 

- `claim_funds_from_htlc_forward_hop(prev_htlc_2)`
  `make_payment_forwarded_event` returns `None`
  `completion_action` returns FreeOtherChannelImmediately`
  - `claim_funds_from_hop`:
    - Called with `prev_htlc_2` as previous hop
    - `claim_mpp_part`:
      - `get_update_fulfill_htlc_and_commit`:
        - Returns a `NewClaim`
    - Push action into `monitor_update_blocked_actions`

This is a consequence of our only ever making a
`FreeOtherChannelImmediately` event type when we had a `DuplicateClaim`
(and thus set `definitely_duplicate`).

## Branch Sync

Have two branches:
- Current PR, needs rebase but is in review
- End to end, rebased on Matt's PRs that I need

Syncing fixups from old branch to new.

Next:

- Start to pull off pieces for next PR!
- Focusing on MPP accumulation of trampoline payments
- Let them accumulate and then reject them on total!

If I muck this up I have a backup on:
backup-2299-end-to-end-02-24-1546

reordering:
- need to add rejection in trampoline-dispatch
- we can then test mpp accumulation up until we fail back thanks to
  parts all arriving and all sorts of restart cases!
- need to re-add handling function in the same place as where we
  allow decoding of htlcsource

Check mpp timeout:
- If we have the full amount, then don't timeout
- If any HTLC is over timeout ticks

## Rebase

Bisecting issue:
- d878040ac is good
- 05f7420c3 is bad

Failure in:
ln/refactor: move mpp timeout check into helper function

- [x] Need to move the "use outgoing in pending" up to before 
  `ln: store next trampoline amount and cltv in PendingHTLCRouting`
  - Reordered these nicely

- [x] Move test compile fix right up to after first commit in upstream
f Test failure belongs on upstream rebase

- [x] Check that `failed_htlcs` on restart push right `HTLCSource` type
  - `shutdown_result.dropped_outbound_htlcs` 
    - Set in `force_shutdown` based on source in `pending_outbound`
  - `get_onchain_failed_outbound_htlcs`
    - Sourced from `counterparty_claimable_outpoints`
      - Set in `provide_latest_counterparty_commitment_tx`
        - Set from `LatestCounterpartyCommitmentTXInfo`
          - Set from `build_commitment_no_status_check`
            - Set from channel's pending htlcs (will be correct type)
  - `channel.get_all_current_outbound_htlcs`: also set from the above
