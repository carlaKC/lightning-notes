# Support Generic HTLC Interception

- Add interception with a bitfield that indicates the types that they
  want to intercept

## Review Round 1

### Drop lockorder comments on ChannelManager

- Removes a comment that has the lock order for ChannelManager

Q: Mentions "automated lockorder issue detection"
- We have a file called `debug_sync.rs` which wraps regular locks
  - Inner lock `StdRwLock` (alias of regular `RwLock`
  - Metadata about the locking order `LockMetadata` (1)

(1) `LockMetadata`
- `lock_idx`: we globally track a counter every time we create a lock
- `locked_before`: `Map<idx, LockMetadata>`
- We can basically check this hashmap back for our own index

-> That is very cool.

### Move HTLC holding into HTLC decode from forward_htlcs

- Async payments added logic to hold htlcs until a message arrives
- This is implemented in `forward_htlcs`, where we take a look at
  `should_hold_htlc`.
  - `forward_htlcs` is called to push HTLCs into our `forward_htlcs`
    map, from which it will be retrieved to start processing the
    outgoing HTLC forward.
- This commit moves the holding logic to `process_pending_update_add_htlcs`

Q: Where is this in the flow?
- `process_pending_htlc_forwards` is polled periodically to process
  our next set of HTLCs
  - `process_pending_update_add_htlcs`: decodes our received
    `update_add_htlcs`, checks we can forward them, then calls
    `forward_htlcs` to push into the map for outgoing processing
  - `process_forward_htlcs`: grabs htlcs out of `forward_htlcs`
    and adds them on the outgoing channel.

When we're in an async payments setting, we're only _ever_ going to
receive a HTLC we want to hold via an `UpdateAddHTLC` (if we were
the originator of the HTLC, we can just hold off on it ourselves).
So we can move our hold processing to `process_pending_update_add_htlcs`,
which is the place where we receive such HTLCs.

Previously (if should_hold_htlc):
- Generate a htlc intercept ID
- Add to our `pending_intercepted_htlcs`
  - Log if inserted
  - Fail back if duplicated

Now (if should hold htlc):
- Generate a htlc intercept ID
- Add to our `pending_intercepted_htlcs`:
  - Log if inserted
  - Push into `htlc_fails` map

Q: How does `fail_intercepted_htlc` handle the failure? Is it the same
   as the `htlc_fail` and `failure_type` that we do in the new code?
- `fail_intercepted_htlc` is able to grab the HTLC out of
  `pending_intercepted_htlcs`:
  - `reason`: `LocalHTLCFailureReason`
  - `destination`: `InvalidForward`
-> The reason has changed, but it kinda makes sense

Q: How has failure handling changed?

Previously:
- `fail_intercepted_htlc` pushes to `fail_intercept_forwards`
- `fail_htlc_backwards_internal` (assuming this is a forward):
  - Creates a failure type based on blinding status
  - Adds `HTLCForwardInfo` to `forward_htlcs`
  - Pushes a `HTLCHandlingFailed`

Now:
- Push into our `htlc_fails` map
- Create `HTLCForwardInfo` based on failure type
- Adds `HTLCForwardInfo` to `forward_htlcs`
- Pushes a `HTLCHandlingFailed`

[x] Pre-existing, but: Can this be DRY-ed up a bit? 
-> Yes it can, done in a commit that follows!

### Fix the HTLC failure reason reported when a peer is offline

- Simple fix of errors + docs.

### DRY HTLC failure paths in process_pending_update_add_htlcs

- Add a macro to DRY up the ugly error handling mentioned above

### Support generic HTLC interception

TODO: resume review on this fresh tomorrow
